  % TRANSFER LEARNING --------------------------
@inproceedings{lazaric2008transfer,
  title={Transfer of samples in batch reinforcement learning},
  author={Lazaric, Alessandro and Restelli, Marcello and Bonarini, Andrea},
  booktitle={Proceedings of the 25th international conference on Machine learning},
  pages={544--551},
  year={2008},
  organization={ACM}
}

@incollection{lazaric2012transfer,
  title={Transfer in reinforcement learning: a framework and a survey},
  author={Lazaric, Alessandro},
  booktitle={Reinforcement Learning},
  pages={143--173},
  year={2012},
  publisher={Springer}
}

@inproceedings{liao2005logistic,
  title={Logistic regression with an auxiliary data source},
  author={Liao, Xuejun and Xue, Ya and Carin, Lawrence},
  booktitle={Proceedings of the 22nd international conference on Machine learning},
  pages={505--512},
  year={2005},
  organization={ACM}
}

@article{pan2010survey,
  title={A survey on transfer learning},
  author={Pan, Sinno Jialin and Yang, Qiang},
  journal={IEEE Transactions on knowledge and data engineering},
  volume={22},
  number={10},
  pages={1345--1359},
  year={2010},
  publisher={IEEE}
}

@inproceedings{pardoe2010boosting,
  title={Boosting for regression transfer},
  author={Pardoe, David and Stone, Peter},
  booktitle={Proceedings of the 27th international conference on Machine learning (ICML-10)},
  pages={863--870},
  year={2010}
}

@article{hanneke2013theory,
  title={A theory of transfer learning with applications to active learning},
  author={Yang, Liu and Hanneke, Steve and Carbonell, Jaime},
  journal={Machine learning},
  volume={90},
  number={2},
  pages={161--189},
  year={2013},
  publisher={Springer}
}

@inproceedings{lazaric2011multiple,
  title={Transfer from multiple MDPs},
  author={Lazaric, Alessandro and Restelli, Marcello},
  booktitle={Advances in Neural Information Processing Systems},
  pages={1746--1754},
  year={2011}
}

% MISC -------------------------------------

@phdthesis{watkins1989learning,
  title={Learning from delayed rewards},
  author={Watkins, Christopher John Cornish Hellaby},
  year={1989},
  school={University of Cambridge England}
}

@inproceedings{singh2004intrinsically,
  title={Intrinsically Motivated Reinforcement Learning.},
  author={Singh, Satinder P and Barto, Andrew G and Chentanez, Nuttapong},
  booktitle={NIPS},
  volume={17},
  number={2},
  pages={1281--1288},
  year={2004}
}

@book{sutton1998reinforcement,
  title={Reinforcement learning: An introduction},
  author={Sutton, Richard S and Barto, Andrew G},
  volume={1},
  number={1},
  year={1998},
  publisher={MIT press Cambridge}
}

@article{ormoneit2002kernel,
  title={Kernel-based reinforcement learning},
  author={Ormoneit, Dirk and Sen, Saunak},
  journal={Machine learning},
  volume={49},
  number={2},
  pages={161--178},
  year={2002},
  publisher={Springer}
}

@article{gordon1999approximate,
  title={Approximate solutions to Markov decision processes},
  author={Gordon, Geoffrey J},
  journal={Robotics Institute},
  pages={228},
  year={1999}
}

@phdthesis{ernst2003near,
  title={Near optimal closed-loop control. Application to electric power systems},
  author={Ernst, Damien},
  year={2003},
  school={University of Liege, Belgium}
}

@article{boyan2002technical,
  title={Technical update: Least-squares temporal difference learning},
  author={Boyan, Justin A},
  journal={Machine Learning},
  volume={49},
  number={2},
  pages={233--246},
  year={2002},
  publisher={Springer}
}

@article{ernst2005tree,
  title={Tree-based batch mode reinforcement learning},
  author={Ernst, Damien and Geurts, Pierre and Wehenkel, Louis},
  journal={Journal of Machine Learning Research},
  volume={6},
  number={Apr},
  pages={503--556},
  year={2005}
}

@inproceedings{neumann2009fitted,
  title={Fitted Q-iteration by advantage weighted regression},
  author={Neumann, Gerhard and Peters, Jan R},
  booktitle={Advances in neural information processing systems},
  pages={1177--1184},
  year={2009}
}

@book{importance2013Owen,
   author = {Art B. Owen},
   year = 2013,
   title = {Monte Carlo theory, methods and examples}
}

@article{fieller1932distribution,
  title={The distribution of the index in a normal bivariate population},
  author={Fieller, EC},
  journal={Biometrika},
  pages={428--440},
  year={1932},
  publisher={JSTOR}
}

@article{bromiley2003products,
  title={Products and convolutions of gaussian probability density functions},
  author={Bromiley, Paul},
  journal={Tina-Vision Memo},
  volume={3},
  number={4},
  year={2003}
}

@article{mnih2015human,
  title={Human-level control through deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A and Veness, Joel and Bellemare, Marc G and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K and Ostrovski, Georg and others},
  journal={Nature},
  volume={518},
  number={7540},
  pages={529--533},
  year={2015},
  publisher={Nature Research}
}

@article{ben2010theory,
  title={A theory of learning from different domains},
  author={Ben-David, Shai and Blitzer, John and Crammer, Koby and Kulesza, Alex and Pereira, Fernando and Vaughan, Jennifer Wortman},
  journal={Machine learning},
  volume={79},
  number={1},
  pages={151--175},
  year={2010},
  publisher={Springer}
}

@article{crammer2008learning,
  title={Learning from multiple sources},
  author={Crammer, Koby and Kearns, Michael and Wortman, Jennifer},
  journal={Journal of Machine Learning Research},
  volume={9},
  number={Aug},
  pages={1757--1774},
  year={2008}
}

@inproceedings{taylor2008transferring,
  title={Transferring instances for model-based reinforcement learning},
  author={Taylor, Matthew E and Jong, Nicholas K and Stone, Peter},
  booktitle={Joint European Conference on Machine Learning and Knowledge Discovery in Databases},
  pages={488--505},
  year={2008},
  organization={Springer}
}

@inproceedings{konidaris2007building,
  title={Building Portable Options: Skill Transfer in Reinforcement Learning.},
  author={Konidaris, George and Barto, Andrew G},
  booktitle={IJCAI},
  volume={7},
  pages={895--900},
  year={2007}
}

@techreport{phillips2006knowledge,
  title={Knowledge transfer in Markov decision processes},
  author={Phillips, Caitlin},
  year={2006},
  institution={Technical report, McGill University, School of Computer Science, 2006. URL http://www. cs. mcgill. ca/cphill/CDMP/summary. pdf}
}

@article{scikit,
 title={Scikit-learn: Machine Learning in {P}ython},
 author={Pedregosa, F. and Varoquaux, G. and Gramfort, A. and Michel, V.
         and Thirion, B. and Grisel, O. and Blondel, M. and Prettenhofer, P.
         and Weiss, R. and Dubourg, V. and Vanderplas, J. and Passos, A. and
         Cournapeau, D. and Brucher, M. and Perrot, M. and Duchesnay, E.},
 journal={Journal of Machine Learning Research},
 volume={12},
 pages={2825--2830},
 year={2011}
}

@inproceedings{atkeson1997comparison,
  title={A comparison of direct and model-based reinforcement learning},
  author={Atkeson, Christopher G and Santamaria, Juan Carlos},
  booktitle={Robotics and Automation, 1997. Proceedings., 1997 IEEE International Conference on},
  volume={4},
  pages={3557--3564},
  year={1997},
  organization={IEEE}
}

@inproceedings{precup2001off,
  title={Off-policy temporal-difference learning with function approximation},
  author={Precup, Doina and Sutton, Richard S and Dasgupta, Sanjoy},
  booktitle={ICML},
  pages={417--424},
  year={2001}
}

@article{singh2000convergence,
  title={Convergence results for single-step on-policy reinforcement-learning algorithms},
  author={Singh, Satinder and Jaakkola, Tommi and Littman, Michael L and Szepesv{\'a}ri, Csaba},
  journal={Machine learning},
  volume={38},
  number={3},
  pages={287--308},
  year={2000},
  publisher={Springer}
}

@inproceedings{huang2005reinforcement,
  title={Reinforcement learning neural network to the problem of autonomous mobile robot obstacle avoidance},
  author={Huang, Bing-Qiang and Cao, Guang-Yi and Guo, Min},
  booktitle={Machine Learning and Cybernetics, 2005. Proceedings of 2005 International Conference on},
  volume={1},
  pages={85--89},
  year={2005},
  organization={IEEE}
}

@inproceedings{sutton2000policy,
  title={Policy gradient methods for reinforcement learning with function approximation},
  author={Sutton, Richard S and McAllester, David A and Singh, Satinder P and Mansour, Yishay},
  booktitle={Advances in neural information processing systems},
  pages={1057--1063},
  year={2000}
}

@comment{BibDesk Smart Groups{
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE plist PUBLIC "-//Apple//DTD PLIST 1.0//EN" "http://www.apple.com/DTDs/PropertyList-1.0.dtd">
<plist version="1.0">
<array>
	<dict>
		<key>conditions</key>
		<array>
			<dict>
				<key>comparison</key>
				<integer>2</integer>
				<key>key</key>
				<string>Keywords</string>
				<key>value</key>
				<string>LaTeX</string>
				<key>version</key>
				<string>1</string>
			</dict>
		</array>
		<key>conjunction</key>
		<integer>0</integer>
		<key>group name</key>
		<string>LaTeX</string>
	</dict>
</array>
</plist>
}}
